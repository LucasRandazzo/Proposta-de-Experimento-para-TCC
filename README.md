# Plano de Experimento ‚Äì Scoping e Planejamento

## 1. Identifica√ß√£o b√°sica

### 1.1 T√≠tulo do experimento
Avalia√ß√£o de um Software com Interface Gr√°fica para Minera√ß√£o Automatizada de Reposit√≥rios GitHub e An√°lise de M√©tricas de Pull Requests utilizando Paralelismo e Checkpoints

### 1.2 ID / c√≥digo
EXP-GH-METRICS-2025-01

### 1.3 Vers√£o do documento e hist√≥rico de revis√£o
| Vers√£o | Data       | Descri√ß√£o                             |
|--------|------------|----------------------------------------|
| v1.0   | 2025-11-21 | Cria√ß√£o inicial do plano de experimento |

### 1.4 Datas (cria√ß√£o, √∫ltima atualiza√ß√£o)
- **Cria√ß√£o:** 21/11/2025  
- **√öltima atualiza√ß√£o:** 21/11/2025  

### 1.5 Autores
- **Lucas Randazzo** ‚Äì Engenharia de Software ‚Äì lucasrandazzo2@gmail.com

### 1.6 Respons√°vel principal (PI)
**Lucas Randazzo**

### 1.7 Projeto / iniciativa relacionada
Este experimento faz parte da proposta de desenvolvimento de um **software instal√°vel com interface gr√°fica**, cujo objetivo √© facilitar a minera√ß√£o de reposit√≥rios GitHub e o c√°lculo de m√©tricas de Pull Requests para fins de an√°lise emp√≠rica em Engenharia de Software.

---

## 2. Contexto e problema

### 2.1 Descri√ß√£o do problema / oportunidade
Pull Requests (PRs) s√£o elementos centrais no processo de revis√£o de c√≥digo em projetos GitHub, influenciando diretamente qualidade, colabora√ß√£o e efici√™ncia no desenvolvimento de software. No entanto, minerar PRs em larga escala para fins de pesquisa apresenta v√°rias dificuldades:

- APIs do GitHub exigem conhecimentos t√©cnicos avan√ßados;
- a coleta manual √© lenta e propensa a erros;
- processos longos podem ser interrompidos e precisariam ser retomados;
- pesquisadores iniciantes enfrentam barreiras para extrair e analisar m√©tricas de PRs.

Assim, surge a oportunidade de desenvolver um **software com interface gr√°fica**, capaz de:

- automatizar a minera√ß√£o de reposit√≥rios;
- extrair, filtrar e consolidar m√©tricas de PRs;
- oferecer melhor observabilidade (progresso, logs, status);
- permitir retomada segura via checkpoints;
- reduzir barreiras para uso por pesquisadores e profissionais.

O problema central √©:

> **Como avaliar se um software com interface gr√°fica melhora a acessibilidade, efici√™ncia e confiabilidade na minera√ß√£o de reposit√≥rios GitHub, mantendo a qualidade das m√©tricas coletadas?**

---

### 2.2 Contexto organizacional e t√©cnico
O experimento ser√° realizado em contexto acad√™mico, no √¢mbito de um curso de Engenharia de Software. O software a ser avaliado est√° em fase de concep√ß√£o e dever√° integrar:

- uma interface gr√°fica amig√°vel ao usu√°rio;
- um pipeline automatizado de consultas √† API do GitHub;
- execu√ß√£o paralela para reduzir tempos de coleta;
- mecanismos de checkpoint para retomada confi√°vel de execu√ß√µes.

O foco n√£o √© apenas a implementa√ß√£o, mas **avaliar experimentalmente** se essa abordagem traz benef√≠cios reais frente aos m√©todos tradicionais de minera√ß√£o, mais t√©cnicos e pouco acess√≠veis.

---

### 2.3 Trabalhos e evid√™ncias pr√©vias

#### **Evid√™ncias internas ‚Äî Laborat√≥rio 03 (Disciplina: Laborat√≥rio de Experimenta√ß√£o de Software)**  
O experimento se apoia no trabalho realizado no **Laborat√≥rio 03** da disciplina de *Laborat√≥rio de Experimenta√ß√£o de Software*, dispon√≠vel em:  
üîó **https://github.com/o-romeroo/lab-experimentacao-03**

Esse laborat√≥rio teve como objetivo analisar m√©tricas de Pull Requests em reposit√≥rios populares do GitHub, seguindo crit√©rios como:

- PRs com status MERGED ou CLOSED;  
- pelo menos uma revis√£o humana;  
- tempo m√≠nimo de an√°lise de 1 hora;  
- m√©tricas de tamanho, tempo, descri√ß√£o e intera√ß√£o.

Foram respondidas quest√µes de pesquisa sobre como tamanho do PR, tempo de an√°lise, intera√ß√µes e descri√ß√£o influenciam a aceita√ß√£o do PR ou o n√∫mero de revis√µes.  
Esse estudo evidenciou a **import√¢ncia de m√©tricas de PRs** e **as dificuldades pr√°ticas de realizar essa minera√ß√£o manualmente**, motivando o desenvolvimento de um software automatizado.

---

#### **Evid√™ncias externas ‚Äî literatura acad√™mica**

A literatura em Minera√ß√£o de Reposit√≥rios de Software (MSR) e Code Review destaca:

- **Import√¢ncia dos PRs como artefatos de colabora√ß√£o e qualidade**  
- **Desafios de minera√ß√£o manual**  
- **Fatores que influenciam a aceita√ß√£o de PRs**

Principais refer√™ncias:

1. **Rahman & Roy (2014)** ‚Äî *An Insight into the Pull Requests of GitHub*  
   üîó https://dl.acm.org/doi/10.1145/2597073.2597121  
   Estuda fatores que diferenciam PRs aceitos de rejeitados em dezenas de projetos open source.

2. **Kalliamvakou et al. (2014)** ‚Äî *The Promises and Perils of Mining GitHub*  
   üîó https://chisel.cs.uvic.ca/pubs/kalliamvakou-MSR2014.pdf  
   Discute limita√ß√µes dos dados da plataforma e riscos ao minerar GitHub sem crit√©rios rigorosos.

3. **Yang et al. (2024)** ‚Äî *A Survey on Modern Code Review: Progresses, Challenges and Opportunities*  
   üîó https://github.com/watreyoung/MCR-Survey  
   Apresenta o estado da arte em revis√£o de c√≥digo moderna.

4. **Vidoni (2022)** ‚Äî *A systematic process for Mining Software Repositories*  
   üîó https://www.sciencedirect.com/science/article/pii/S0950584921002317  
   SLR sobre t√©cnicas e desafios da minera√ß√£o de reposit√≥rios.

5. **Wessel et al. (2023)** ‚Äî *GitHub Actions: The Impact on the Pull Request Process*  
   üîó https://www.ime.usp.br/~gerosa/papers/Wessel_EMSE_Actions.pdf  
   Investiga como automa√ß√µes afetam PRs.

Essas evid√™ncias refor√ßam a relev√¢ncia cient√≠fica do tema e a necessidade de ferramentas de minera√ß√£o mais acess√≠veis e automatizadas.

---

### 2.4 Referencial te√≥rico e emp√≠rico essencial

O experimento fundamenta-se em quatro eixos:

#### **(1) Minera√ß√£o de Reposit√≥rios de Software (MSR)**  
Base te√≥rica para extrair e analisar artefatos como PRs.  
Refer√™ncia:  
üîó Kalliamvakou et al. (2014) ‚Äì https://chisel.cs.uvic.ca/pubs/kalliamvakou-MSR2014.pdf

#### **(2) M√©tricas de Pull Requests**  
M√©tricas como tamanho, intera√ß√£o e tempo de an√°lise s√£o amplamente utilizadas na literatura para caracterizar processos de revis√£o.  
Refer√™ncia:  
üîó Rahman & Roy (2014) ‚Äì https://dl.acm.org/doi/10.1145/2597073.2597121

#### **(3) Paralelismo e Toler√¢ncia a Falhas**  
Conceitos herdados de sistemas distribu√≠dos orientam o uso de paralelismo e checkpoints para lidar com execu√ß√µes longas.

#### **(4) Interfaces gr√°ficas e usabilidade**  
GUI melhora observabilidade e acessibilidade em ferramentas t√©cnicas.  
Baseado em princ√≠pios cl√°ssicos de IHC (Norman, Nielsen).

---

## 3. Objetivos e quest√µes (Goal / Question / Metric)

### 3.1 Objetivo geral (Goal Template)

**Analisar** a efic√°cia de um software com interface gr√°fica para minera√ß√£o automatizada de reposit√≥rios GitHub e coleta de m√©tricas de Pull Requests, **com o prop√≥sito de** avaliar sua efici√™ncia, confiabilidade, completude e usabilidade, **sob a perspectiva** de pesquisadores e usu√°rios t√©cnicos, **no contexto** de estudos emp√≠ricos em Engenharia de Software que demandam extra√ß√£o de dados em larga escala.

### 3.2 Objetivos espec√≠ficos

- **OE1 ‚Äì Efici√™ncia:** Avaliar se o software GUI melhora o desempenho da minera√ß√£o em termos de tempo total, throughput e paralelismo.
- **OE2 ‚Äì Confiabilidade:** Avaliar a resili√™ncia do processo, especialmente quanto √† recupera√ß√£o via checkpoints e redu√ß√£o de falhas.
- **OE3 ‚Äì Completude:** Avaliar se as m√©tricas de PRs coletadas pela ferramenta s√£o completas e consistentes em rela√ß√£o ao baseline tradicional.
- **OE4 ‚Äì Usabilidade:** Avaliar a acessibilidade e facilidade de uso do software para usu√°rios com n√≠veis variados de experi√™ncia.

### 3.3 Quest√µes de pesquisa

#### **Para OE1 ‚Äì Efici√™ncia**
- **Q1.1:** O software reduz o tempo total de minera√ß√£o?
- **Q1.2:** O software aumenta o throughput (PRs/min, repos/hora)?
- **Q1.3:** O uso de paralelismo no software melhora o desempenho?

#### **Para OE2 ‚Äì Confiabilidade**
- **Q2.1:** O software apresenta menos falhas que o m√©todo tradicional?
- **Q2.2:** Os checkpoints permitem retomada eficaz ap√≥s interrup√ß√µes?
- **Q2.3:** O sistema registra e sinaliza erros de forma adequada?

#### **Para OE3 ‚Äì Completude**
- **Q3.1:** O software coleta a mesma quantidade de PRs que o m√©todo baseline?
- **Q3.2:** As m√©tricas de PR s√£o equivalentes entre m√©todos?
- **Q3.3:** H√° perda de dados causada pelo paralelismo?

#### **Para OE4 ‚Äì Usabilidade**
- **Q4.1:** Os usu√°rios conseguem completar tarefas sem dificuldade?
- **Q4.2:** A interface gr√°fica √© percebida como intuitiva?
- **Q4.3:** Os usu√°rios preferem a GUI ao m√©todo tradicional?

### 3.4 M√©tricas associadas (GQM)

#### **Tabela GQM**

| Objetivo | Pergunta | M√©tricas associadas |
|----------|----------|----------------------|
| OE1 | Q1.1 | M1 ‚Äì Tempo total de execu√ß√£o; M2 ‚Äì Tempo m√©dio por reposit√≥rio |
| OE1 | Q1.2 | M3 ‚Äì PRs/min; M4 ‚Äì Reposit√≥rios/hora |
| OE1 | Q1.3 | M5 ‚Äì Tempo m√©dio por thread; M6 ‚Äì Speedup |
| OE2 | Q2.1 | M7 ‚Äì Taxa de falhas; M8 ‚Äì Interrup√ß√µes n√£o tratadas |
| OE2 | Q2.2 | M9 ‚Äì Progresso recuperado; M10 ‚Äì Tempo de retomada |
| OE2 | Q2.3 | M11 ‚Äì Eventos de erro registrados; M12 ‚Äì Tempo de detec√ß√£o |
| OE3 | Q3.1 | M13 ‚Äì Percentual de PRs coletados; M14 ‚Äì Diferen√ßa absoluta de PRs |
| OE3 | Q3.2 | M15 ‚Äì Correla√ß√£o entre m√©tricas; M16 ‚Äì Diferen√ßa m√©dia |
| OE3 | Q3.3 | M17 ‚Äì PRs perdidos por thread; M18 ‚Äì M√©tricas incompletas (%) |
| OE4 | Q4.1 | M19 ‚Äì Tempo para completar tarefa; M20 ‚Äì Taxa de sucesso |
| OE4 | Q4.2 | M21 ‚Äì SUS Score; M22 ‚Äì Erros cometidos pelo usu√°rio |
| OE4 | Q4.3 | M23 ‚Äì Prefer√™ncia declarada; M24 ‚Äì Satisfa√ß√£o geral |

---

### **Tabela abrangente de m√©tricas**

| C√≥digo | Nome da m√©trica | Descri√ß√£o | Unidade | Fonte dos dados |
|--------|------------------|-----------|----------|------------------|
| M1 | Tempo total de execu√ß√£o | Tempo total do processo de minera√ß√£o | minutos | logs do sistema |
| M2 | Tempo m√©dio por reposit√≥rio | M√©dia de tempo gasto em cada reposit√≥rio | minutos | logs do sistema |
| M3 | PRs por minuto | Throughput da minera√ß√£o | PR/min | contagem de PRs |
| M4 | Reposit√≥rios por hora | Fluxo de processamento | repos/hora | logs do sistema |
| M5 | Tempo m√©dio por thread | Tempo m√©dio de execu√ß√£o paralela | minutos | logs de threads |
| M6 | Speedup | Raz√£o entre execu√ß√£o paralela e sequencial | adimensional | compara√ß√£o experimental |
| M7 | Taxa de falhas | Propor√ß√£o de execu√ß√µes com erros | % | relat√≥rios de erro |
| M8 | Interrup√ß√µes n√£o tratadas | Falhas que n√£o foram recuperadas | contagem | logs |
| M9 | Progresso recuperado | Percentual restaurado ap√≥s retomada | % | checkpoints |
| M10 | Tempo de retomada | Tempo entre falha e retomada | segundos | tempo de execu√ß√£o |
| M11 | Eventos de erro | N√∫mero de erros detectados | contagem | logs |
| M12 | Tempo de detec√ß√£o de falha | Tempo at√© identificar erro | segundos | logs |
| M13 | Percentual de PRs coletados | % de PRs coletados vs baseline | % | compara√ß√£o de datasets |
| M14 | Diferen√ßa de PRs | Quantidade absoluta coletada a menos ou a mais | contagem | datasets |
| M15 | Correla√ß√£o entre m√©tricas | Correla√ß√£o Pearson/Spearman entre m√©todos | coeficiente | c√°lculo estat√≠stico |
| M16 | Diferen√ßa m√©dia das m√©tricas | Diferen√ßas absolutas normalizadas | valor m√©dio | estat√≠stica |
| M17 | PRs perdidos por thread | PRs descartados por falha de thread | contagem | logs |
| M18 | M√©tricas incompletas | Percentual de PRs com campos ausentes | % | dataset final |
| M19 | Tempo para completar tarefa | Tempo para usu√°rio executar a√ß√£o | minutos | teste de usabilidade |
| M20 | Taxa de sucesso | % de tarefas conclu√≠das sem erro | % | sess√£o de testes |
| M21 | SUS Score | Nota do System Usability Scale | pontos (0‚Äì100) | question√°rio SUS |
| M22 | Erros do usu√°rio | Quantidade de erros cometidos | contagem | observa√ß√£o |
| M23 | Prefer√™ncia declarada | % de usu√°rios que preferem a GUI | % | question√°rio |
| M24 | Satisfa√ß√£o geral | Avalia√ß√£o do usu√°rio | Likert (1‚Äì5) | question√°rio |

---

## 4. Escopo e contexto do experimento

### 4.1 Escopo funcional / de processo

**Inclu√≠do:**
- execu√ß√£o do software GUI para minera√ß√£o de PRs;
- compara√ß√£o com baseline baseado em scripts;
- coleta de m√©tricas de efici√™ncia, confiabilidade e completude;
- aplica√ß√£o de testes de usabilidade.

**Exclu√≠do:**
- an√°lise qualitativa do conte√∫do dos PRs;
- uso de APIs privadas ou datasets externos;
- avalia√ß√£o do c√≥digo interno do software.

### 4.2 Contexto do estudo

O estudo ocorrer√° em ambiente acad√™mico, no contexto de um projeto de Engenharia de Software. Os participantes incluem estudantes e pesquisadores com familiaridade intermedi√°ria com GitHub. O projeto analisado n√£o √© cr√≠tico, mas envolve manipula√ß√£o de grande volume de dados e execu√ß√£o prolongada.

### 4.3 Premissas

- A API do GitHub estar√° funcional durante o experimento.  
- O ambiente ter√° conex√£o est√°vel.  
- Os participantes ter√£o conhecimento b√°sico sobre PRs.  
- O software GUI estar√° funcional e est√°vel para testes.

### 4.4 Restri√ß√µes

- Tempo limitado de execu√ß√£o em laborat√≥rio;  
- Disponibilidade limitada de tokens da API GitHub;  
- Equipamentos com desempenho heterog√™neo;  
- Amostra pequena de usu√°rios para testes.

### 4.5 Limita√ß√µes previstas

- Resultados podem n√£o generalizar para ambientes industriais;  
- A variabilidade de comportamento da API pode afetar a medi√ß√£o;  
- Perfil limitado dos participantes reduz validade externa.

---

## 5. Stakeholders e impacto esperado

### 5.1 Stakeholders principais

- Pesquisadores  
- Estudantes  
- Professores/orientadores  
- Desenvolvedores  
- Comunidade MSR  

### 5.2 Interesses e expectativas

| Stakeholder | Expectativas |
|-------------|--------------|
| Pesquisadores | Maior produtividade, datasets consistentes |
| Estudantes | Ferramenta f√°cil de usar |
| Professores | Estudos reprodut√≠veis |
| Desenvolvedores | An√°lises internas de code review |
| Comunidade MSR | Metodologia replic√°vel |

### 5.3 Impactos potenciais

- Redu√ß√£o de tempo de minera√ß√£o;  
- Aumento da confiabilidade da coleta;  
- Facilita√ß√£o de estudos emp√≠ricos;  
- Poss√≠vel modifica√ß√£o do processo tradicional de coleta de dados.  

---

## 6. Riscos de alto n√≠vel, premissas e crit√©rios de sucesso

### 6.1 Riscos de alto n√≠vel

- Falhas de rede ou API do GitHub;  
- Dados incompletos por limita√ß√µes de request;  
- Baixa aceita√ß√£o da GUI pelos usu√°rios;  
- Falhas cr√≠ticas sem recupera√ß√£o via checkpoint.

### 6.2 Crit√©rios de sucesso globais

- Coleta de ‚â• 95% dos PRs do baseline;  
- Tempo de execu√ß√£o ‚â§ baseline;  
- SUS ‚â• 70;  
- Taxa de falhas reduzida ou mitigada.

### 6.3 Crit√©rios de parada antecipada

- Indisponibilidade da API GitHub;  
- Falha cr√≠tica no software GUI;  
- Ambiente inadequado para execu√ß√£o;  
- Mudan√ßa de escopo institucional.

---

## 7. Modelo conceitual e hip√≥teses

### 7.1 Modelo conceitual do experimento

O experimento baseia-se na premissa de que a **forma de execu√ß√£o do processo de minera√ß√£o de Pull Requests (GUI vs Script)** atua como um fator que **modifica o comportamento do sistema de coleta de dados** em tr√™s dimens√µes principais:

1. **Efici√™ncia**
   - Tempo total de execu√ß√£o
   - Throughput (PRs/min, reposit√≥rios/hora)
   - Speedup obtido pelo paralelismo da GUI

2. **Confiabilidade**
   - Ocorr√™ncia de falhas
   - Capacidade de retomada via checkpoints
   - Estabilidade da execu√ß√£o

3. **Completude**
   - Quantidade de PRs coletados
   - Integridade das m√©tricas de PR
   - Consist√™ncia entre execu√ß√µes

Essas dimens√µes, influenciadas pelo fator ‚ÄúForma de Execu√ß√£o‚Äù, refletem-se diretamente nas **m√©tricas produzidas no dataset final**, permitindo avaliar rigorosamente o impacto entre os dois m√©todos.

---

### 7.2 Hip√≥teses formais (H0, H1)

#### Efici√™ncia
- **H0-E1:** N√£o h√° diferen√ßa significativa no tempo total de minera√ß√£o entre GUI e Script.  
- **H1-E1:** A GUI reduz o tempo total de minera√ß√£o.

- **H0-E2:** O throughput n√£o difere entre os m√©todos.  
- **H1-E2:** A GUI aumenta o throughput.

#### Confiabilidade
- **H0-C1:** A taxa de falhas √© equivalente entre GUI e Script.  
- **H1-C1:** A GUI apresenta menor taxa de falhas.

- **H0-C2:** O uso de checkpoints n√£o melhora a retomada.  
- **H1-C2:** A GUI possibilita retomada mais eficaz.

#### Completude
- **H0-K1:** A quantidade de PRs coletados √© igual nos dois m√©todos.  
- **H1-K1:** H√° diferen√ßa significativa na quantidade de PRs coletados.

- **H0-K2:** As m√©tricas coletadas s√£o equivalentes entre os m√©todos.  
- **H1-K2:** As m√©tricas coletadas diferem significativamente.

---

### 7.3 N√≠vel de signific√¢ncia e considera√ß√µes de poder

- **N√≠vel de signific√¢ncia**: Œ± = 0,05  
- **Poder estat√≠stico esperado**: ‚â• 0,80  

A grande quantidade de PRs e reposit√≥rios envolvidos tende a fornecer tamanho amostral adequado para detec√ß√£o de diferen√ßas reais entre os tratamentos.

---

## 8. Vari√°veis, fatores, tratamentos e objetos de estudo

### 8.1 Objetos de estudo
- Reposit√≥rios GitHub selecionados.
- Conjuntos de Pull Requests v√°lidos.
- Execu√ß√µes completas dos processos de coleta via GUI e via Script.

---

### 8.2 Sujeitos / participantes (vis√£o geral)
- Pesquisadores, estudantes ou usu√°rios t√©cnicos.
- Respons√°veis apenas por acionar os m√©todos e registrar resultados.

---

### 8.3 Vari√°veis independentes (fatores) e seus n√≠veis

| Tipo | Nome | Descri√ß√£o | N√≠veis |
|------|------|------------|--------|
| Fator principal | Forma de execu√ß√£o | M√©todo utilizado para minerar PRs | GUI, Script |

---

### 8.4 Tratamentos (condi√ß√µes experimentais)

| Tratamento | Descri√ß√£o |
|------------|-----------|
| T1 ‚Äî GUI | Execu√ß√£o completa utilizando o software com interface gr√°fica |
| T2 ‚Äî Script | Execu√ß√£o completa utilizando scripts tradicionais em linha de comando |

---

### 8.5 Vari√°veis dependentes (respostas)

| Vari√°vel | Descri√ß√£o |
|----------|-----------|
| Tempo total | Tempo total de minera√ß√£o |
| Throughput | PRs por minuto / reposit√≥rios por hora |
| Speedup | Ganho relativo obtido com paralelismo |
| Taxa de falhas | Propor√ß√£o de execu√ß√µes com erros |
| PRs coletados | Quantidade total de PRs coletados |
| Qualidade das m√©tricas | Completude e consist√™ncia dos dados |

---

### 8.6 Vari√°veis de controle / bloqueio

| Vari√°vel | Como ser√° controlada |
|----------|-----------------------|
| Lista de reposit√≥rios | Mesma lista em ambos os m√©todos |
| Ambiente | Mesma m√°quina e conex√£o |
| Tokens da API | Mesma distribui√ß√£o e quantidade |
| Per√≠odo | Execu√ß√µes realizadas no mesmo intervalo |

---

### 8.7 Vari√°veis de confus√£o conhecidas

| Poss√≠vel confusor | Estrat√©gia de mitiga√ß√£o |
|-------------------|--------------------------|
| Instabilidade da API do GitHub | Monitoramento e repeti√ß√£o controlada |
| Oscila√ß√µes de rede | Ambiente fixo e monitorado |
| Comportamento de threads | Execu√ß√µes replicadas e logs detalhados |

---

### Tabela geral de vari√°veis

| Tipo | Nome | Descri√ß√£o |
|------|------|------------|
| Independente | Forma de execu√ß√£o | GUI vs Script |
| Dependente | Tempo total | Medida de efici√™ncia |
| Dependente | Throughput | Fluxo de processamento |
| Dependente | Speedup | Ganho obtido em paralelismo |
| Dependente | Taxa de falhas | Confiabilidade |
| Dependente | PRs coletados | Completude |
| Dependente | Diferen√ßa das m√©tricas | Qualidade dos dados |
| Controle | Reposit√≥rios | Lista fixa |
| Controle | Ambiente | Hardware/software id√™nticos |
| Confus√£o | API GitHub | Vari√°vel externa |

---

### Tabela de fatores, tratamentos e combina√ß√µes

Como o experimento possui apenas um fator bin√°rio, as combina√ß√µes s√£o simples:

| Fator | N√≠veis | Combina√ß√£o |
|-------|--------|------------|
| Forma de execu√ß√£o | GUI | GUI |
| Forma de execu√ß√£o | Script | Script |

---

## 9. Desenho experimental

### 9.1 Tipo de desenho
Desenho **completamente randomizado**, com dois tratamentos (GUI e Script).  
Adequado porque:

- Reposit√≥rios s√£o independentes.
- Execu√ß√£o autom√°tica evita efeitos de aprendizagem.
- Simplicidade e robustez em compara√ß√µes diretas.

---

### 9.2 Randomiza√ß√£o e aloca√ß√£o
- Reposit√≥rios ser√£o distribu√≠dos aleatoriamente entre os dois tratamentos.
- A ordem das execu√ß√µes tamb√©m ser√° randomizada.
- Ser√° utilizada uma semente fixa (**seed = 42**) para manter reprodutibilidade.

---

### 9.3 Balanceamento e contrabalan√ßo
- A divis√£o ser√° balanceada (mesmo n√∫mero aproximado de reposit√≥rios por tratamento).
- O contrabalan√ßo pode ser aplicado por meio de invers√£o da ordem de execu√ß√£o (GUI ‚Üí Script e Script ‚Üí GUI), se necess√°rio.
- Como o processo √© automatizado, os efeitos de ordem s√£o negligenci√°veis.

---

### 9.4 N√∫mero de grupos e sess√µes
- **Grupos:** 2 (GUI e Script)
- **Sess√µes:** Cada grupo executar√° o processo completo uma vez, com possibilidade de repeti√ß√£o para refor√ßar an√°lise estat√≠stica.

---

## 10. Popula√ß√£o, sujeitos e amostragem

### 10.1 Popula√ß√£o-alvo
Descreva qual √© a popula√ß√£o real que voc√™ deseja representar com o experimento (por exemplo, ‚Äúdesenvolvedores Java de times de produto web‚Äù).

### 10.2 Crit√©rios de inclus√£o de sujeitos
Especifique os requisitos m√≠nimos para um participante ser eleg√≠vel (experi√™ncia, conhecimento, papel, disponibilidade, etc.).

### 10.3 Crit√©rios de exclus√£o de sujeitos
Liste condi√ß√µes que impedem participa√ß√£o (conflitos de interesse, falta de skills essenciais, restri√ß√µes legais ou √©ticas).

### 10.4 Tamanho da amostra planejado (por grupo)
Defina quantos participantes voc√™ pretende ter no total e em cada grupo, relacionando a decis√£o com poder, recursos e contexto.

### 10.5 M√©todo de sele√ß√£o / recrutamento
Explique como os participantes ser√£o escolhidos (amostra de conveni√™ncia, sorteio, convite aberto, turma de disciplina, time espec√≠fico).

### 10.6 Treinamento e prepara√ß√£o dos sujeitos
Descreva qual treinamento ou material preparat√≥rio ser√° fornecido para nivelar entendimento e reduzir vieses por falta de conhecimento.

---

## 11. Instrumenta√ß√£o e protocolo operacional

### 11.1 Instrumentos de coleta (question√°rios, logs, planilhas, etc.)
Liste todos os instrumentos que ser√£o usados para coletar dados (arquivos, formul√°rios, scripts, ferramentas), com uma breve descri√ß√£o do papel de cada um.

### 11.2 Materiais de suporte (instru√ß√µes, guias)
Descreva as instru√ß√µes escritas, guias r√°pidos, slides ou outros materiais que ser√£o fornecidos a participantes e administradores do experimento.

### 11.3 Procedimento experimental (protocolo ‚Äì vis√£o passo a passo)
Escreva, em ordem, o que acontecer√° na opera√ß√£o (do convite ao encerramento), de modo que algu√©m consiga executar o experimento seguindo esse roteiro.

### 11.4 Plano de piloto (se haver√° piloto, escopo e crit√©rios de ajuste)
Indique se um piloto ser√° realizado, com que participantes e objetivos, e defina que tipo de ajuste do protocolo poder√° ser feito com base nesse piloto.

---

## 12. Plano de an√°lise de dados (pr√©-execu√ß√£o)

### 12.1 Estrat√©gia geral de an√°lise (como responder√° √†s quest√µes)
Explique, em alto n√≠vel, como os dados coletados ser√£o usados para responder cada quest√£o de pesquisa ou de neg√≥cio.

### 12.2 M√©todos estat√≠sticos planejados
Liste os principais testes ou t√©cnicas estat√≠sticas que pretende usar (por exemplo, t-teste, ANOVA, testes n√£o param√©tricos, regress√£o).

### 12.3 Tratamento de dados faltantes e outliers
Defina previamente as regras para lidar com dados ausentes e valores extremos, evitando decis√µes oportunistas ap√≥s ver os resultados.

### 12.4 Plano de an√°lise para dados qualitativos (se houver)
Descreva como voc√™ tratar√° dados qualitativos (entrevistas, coment√°rios, observa√ß√µes), especificando a t√©cnica de an√°lise (codifica√ß√£o, categorias, etc.).

---

## 13. Avalia√ß√£o de validade (amea√ßas e mitiga√ß√£o)

### 13.1 Validade de conclus√£o
Liste amea√ßas que podem comprometer a robustez das conclus√µes estat√≠sticas (baixo poder, viola√ß√£o de suposi√ß√µes, erros de medida) e como pretende mitig√°-las.

### 13.2 Validade interna
Identifique amea√ßas relacionadas a causas alternativas para os efeitos observados (history, maturation, selection, etc.) e explique suas estrat√©gias de controle.

### 13.3 Validade de constructo
Refleta se as medidas escolhidas realmente representam os conceitos de interesse e descreva como voc√™ reduzir√° ambiguidades de interpreta√ß√£o.

### 13.4 Validade externa
Discuta em que contextos os resultados podem ser generalizados e quais diferen√ßas de cen√°rio podem limitar essa generaliza√ß√£o.

### 13.5 Resumo das principais amea√ßas e estrat√©gias de mitiga√ß√£o
Fa√ßa uma s√≠ntese das amea√ßas mais cr√≠ticas e das a√ß√µes planejadas, de prefer√™ncia em forma de lista ou tabela simples.

---

## 14. √âtica, privacidade e conformidade

### 14.1 Quest√µes √©ticas (uso de sujeitos, incentivos, etc.)
Descreva potenciais quest√µes √©ticas (press√£o para participar, uso de estudantes, incentivos, riscos de exposi√ß√£o) e como ser√£o tratadas.

### 14.2 Consentimento informado
Explique como os participantes ser√£o informados sobre objetivos, riscos, benef√≠cios e como registrar√£o seu consentimento.

### 14.3 Privacidade e prote√ß√£o de dados
Indique que dados pessoais ser√£o coletados, como ser√£o protegidos (anonimiza√ß√£o, pseudoanonimiza√ß√£o, controle de acesso) e por quanto tempo ser√£o mantidos.

### 14.4 Aprova√ß√µes necess√°rias (comit√™ de √©tica, jur√≠dico, DPO, etc.)
Liste √≥rg√£os ou pessoas que precisam aprovar o experimento (comit√™ de √©tica, jur√≠dico, DPO, gestores) e o status atual dessas aprova√ß√µes.

---

## 15. Recursos, infraestrutura e or√ßamento

### 15.1 Recursos humanos e pap√©is
Identifique os membros da equipe do experimento e descreva brevemente o papel e responsabilidade de cada um.

### 15.2 Infraestrutura t√©cnica necess√°ria
Liste ambientes, servidores, ferramentas, reposit√≥rios e integra√ß√µes que devem estar dispon√≠veis para executar o experimento.

### 15.3 Materiais e insumos
Relacione materiais f√≠sicos ou digitais necess√°rios (m√°quinas, licen√ßas, formul√°rios, dispositivos) que precisam estar prontos antes da opera√ß√£o.

### 15.4 Or√ßamento e custos estimados
Fa√ßa uma estimativa dos principais custos envolvidos (horas de pessoas, servi√ßos, licen√ßas, infraestrutura) e a fonte de financiamento.

---

## 16. Cronograma, marcos e riscos operacionais

### 16.1 Macrocronograma (at√© o in√≠cio da execu√ß√£o)
Defina as principais datas e marcos (conclus√£o do plano, piloto, revis√£o, in√≠cio da opera√ß√£o) com uma vis√£o de tempo realista.

### 16.2 Depend√™ncias entre atividades
Indique quais atividades dependem de outras para come√ßar (por exemplo, treinamento ap√≥s aprova√ß√£o √©tica), deixando essas depend√™ncias claras.

### 16.3 Riscos operacionais e plano de conting√™ncia
Liste riscos ligados a cronograma, disponibilidade de pessoas ou recursos, e descreva a√ß√µes de conting√™ncia caso esses riscos se materializem.

---

## 17. Governan√ßa do experimento

### 17.1 Pap√©is e responsabilidades formais
Defina quem decide, quem executa, quem revisa e quem apenas deve ser informado, deixando claro o fluxo de responsabilidade.

### 17.2 Ritos de acompanhamento pr√©-execu√ß√£o
Descreva as reuni√µes, checkpoints e revis√µes previstos antes da execu√ß√£o, incluindo frequ√™ncia e participantes.

### 17.3 Processo de controle de mudan√ßas no plano
Explique como mudan√ßas no desenho ou no escopo do experimento ser√£o propostas, analisadas, aprovadas e registradas.

---

## 18. Plano de documenta√ß√£o e reprodutibilidade

### 18.1 Reposit√≥rios e conven√ß√µes de nomea√ß√£o
Indique onde o plano, instrumentos, scripts e dados (futuros) ser√£o armazenados e quais conven√ß√µes de nomes ser√£o usadas.

### 18.2 Templates e artefatos padr√£o
Liste os modelos (question√°rios, formul√°rios, checklists, scripts) que ser√£o usados e onde podem ser encontrados.

### 18.3 Plano de empacotamento para replica√ß√£o futura
Descreva o que ser√° organizado desde j√° (documentos, scripts, instru√ß√µes) para facilitar a replica√ß√£o do experimento por outras equipes ou no futuro.

---

## 19. Plano de comunica√ß√£o

### 19.1 P√∫blicos e mensagens-chave pr√©-execu√ß√£o
Liste os grupos que precisam ser comunicados e quais mensagens principais devem receber (objetivos, escopo, datas, impactos esperados).

### 19.2 Canais e frequ√™ncia de comunica√ß√£o
Defina por quais canais (e-mail, reuni√µes, Slack/Teams, etc.) e com que frequ√™ncia as comunica√ß√µes ser√£o feitas.

### 19.3 Pontos de comunica√ß√£o obrigat√≥rios
Especifique os eventos que exigem comunica√ß√£o formal (aprova√ß√£o do plano, mudan√ßas relevantes, adiamentos, cancelamentos).

---

## 20. Crit√©rios de prontid√£o para execu√ß√£o (Definition of Ready)

### 20.1 Checklist de prontid√£o (itens que devem estar completos)
Liste os itens que precisam estar finalizados e aprovados (plano, instrumentos, aprova√ß√£o √©tica, recursos, comunica√ß√£o) para autorizar o in√≠cio da opera√ß√£o.

### 20.2 Aprova√ß√µes finais para iniciar a opera√ß√£o
Indique quem precisa dar o ‚Äúok final‚Äù (nomes ou cargos) e como esse aceite ser√° registrado antes da execu√ß√£o come√ßar.





