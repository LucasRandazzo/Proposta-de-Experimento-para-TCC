# Plano de Experimento â€“ Scoping e Planejamento

## 1. IdentificaÃ§Ã£o bÃ¡sica

### 1.1 TÃ­tulo do experimento
AvaliaÃ§Ã£o de um Software com Interface GrÃ¡fica para MineraÃ§Ã£o Automatizada de RepositÃ³rios GitHub e AnÃ¡lise de MÃ©tricas de Pull Requests utilizando Paralelismo e Checkpoints

### 1.2 ID / cÃ³digo
EXP-GH-METRICS-2025-01

### 1.3 VersÃ£o do documento e histÃ³rico de revisÃ£o
| VersÃ£o | Data       | DescriÃ§Ã£o                             |
|--------|------------|----------------------------------------|
| v1.0   | 2025-11-21 | CriaÃ§Ã£o inicial do plano de experimento |

### 1.4 Datas (criaÃ§Ã£o, Ãºltima atualizaÃ§Ã£o)
- **CriaÃ§Ã£o:** 21/11/2025  
- **Ãšltima atualizaÃ§Ã£o:** 21/11/2025  

### 1.5 Autores
- **Lucas Randazzo** â€“ Engenharia de Software â€“ lucasrandazzo2@gmail.com

### 1.6 ResponsÃ¡vel principal (PI)
**Lucas Randazzo**

### 1.7 Projeto / iniciativa relacionada
Este experimento faz parte da proposta de desenvolvimento de um **software instalÃ¡vel com interface grÃ¡fica**, cujo objetivo Ã© facilitar a mineraÃ§Ã£o de repositÃ³rios GitHub e o cÃ¡lculo de mÃ©tricas de Pull Requests para fins de anÃ¡lise empÃ­rica em Engenharia de Software.

---

## 2. Contexto e problema

### 2.1 DescriÃ§Ã£o do problema / oportunidade
Pull Requests (PRs) sÃ£o elementos centrais no processo de revisÃ£o de cÃ³digo em projetos GitHub, influenciando diretamente qualidade, colaboraÃ§Ã£o e eficiÃªncia no desenvolvimento de software. No entanto, minerar PRs em larga escala para fins de pesquisa apresenta vÃ¡rias dificuldades:

- APIs do GitHub exigem conhecimentos tÃ©cnicos avanÃ§ados;
- a coleta manual Ã© lenta e propensa a erros;
- processos longos podem ser interrompidos e precisariam ser retomados;
- pesquisadores iniciantes enfrentam barreiras para extrair e analisar mÃ©tricas de PRs.

Assim, surge a oportunidade de desenvolver um **software com interface grÃ¡fica**, capaz de:

- automatizar a mineraÃ§Ã£o de repositÃ³rios;
- extrair, filtrar e consolidar mÃ©tricas de PRs;
- oferecer melhor observabilidade (progresso, logs, status);
- permitir retomada segura via checkpoints;
- reduzir barreiras para uso por pesquisadores e profissionais.

O problema central Ã©:

> **Como avaliar se um software com interface grÃ¡fica melhora a acessibilidade, eficiÃªncia e confiabilidade na mineraÃ§Ã£o de repositÃ³rios GitHub, mantendo a qualidade das mÃ©tricas coletadas?**

---

### 2.2 Contexto organizacional e tÃ©cnico
O experimento serÃ¡ realizado em contexto acadÃªmico, no Ã¢mbito de um curso de Engenharia de Software. O software a ser avaliado estÃ¡ em fase de concepÃ§Ã£o e deverÃ¡ integrar:

- uma interface grÃ¡fica amigÃ¡vel ao usuÃ¡rio;
- um pipeline automatizado de consultas Ã  API do GitHub;
- execuÃ§Ã£o paralela para reduzir tempos de coleta;
- mecanismos de checkpoint para retomada confiÃ¡vel de execuÃ§Ãµes.

O foco nÃ£o Ã© apenas a implementaÃ§Ã£o, mas **avaliar experimentalmente** se essa abordagem traz benefÃ­cios reais frente aos mÃ©todos tradicionais de mineraÃ§Ã£o, mais tÃ©cnicos e pouco acessÃ­veis.

---

### 2.3 Trabalhos e evidÃªncias prÃ©vias

#### **EvidÃªncias internas â€” LaboratÃ³rio 03 (Disciplina: LaboratÃ³rio de ExperimentaÃ§Ã£o de Software)**  
O experimento se apoia no trabalho realizado no **LaboratÃ³rio 03** da disciplina de *LaboratÃ³rio de ExperimentaÃ§Ã£o de Software*, disponÃ­vel em:  
ğŸ”— **https://github.com/o-romeroo/lab-experimentacao-03**

Esse laboratÃ³rio teve como objetivo analisar mÃ©tricas de Pull Requests em repositÃ³rios populares do GitHub, seguindo critÃ©rios como:

- PRs com status MERGED ou CLOSED;  
- pelo menos uma revisÃ£o humana;  
- tempo mÃ­nimo de anÃ¡lise de 1 hora;  
- mÃ©tricas de tamanho, tempo, descriÃ§Ã£o e interaÃ§Ã£o.

Foram respondidas questÃµes de pesquisa sobre como tamanho do PR, tempo de anÃ¡lise, interaÃ§Ãµes e descriÃ§Ã£o influenciam a aceitaÃ§Ã£o do PR ou o nÃºmero de revisÃµes.  
Esse estudo evidenciou a **importÃ¢ncia de mÃ©tricas de PRs** e **as dificuldades prÃ¡ticas de realizar essa mineraÃ§Ã£o manualmente**, motivando o desenvolvimento de um software automatizado.

---

#### **EvidÃªncias externas â€” literatura acadÃªmica**

A literatura em MineraÃ§Ã£o de RepositÃ³rios de Software (MSR) e Code Review destaca:

- **ImportÃ¢ncia dos PRs como artefatos de colaboraÃ§Ã£o e qualidade**  
- **Desafios de mineraÃ§Ã£o manual**  
- **Fatores que influenciam a aceitaÃ§Ã£o de PRs**

Principais referÃªncias:

1. **Rahman & Roy (2014)** â€” *An Insight into the Pull Requests of GitHub*  
   ğŸ”— https://dl.acm.org/doi/10.1145/2597073.2597121  
   Estuda fatores que diferenciam PRs aceitos de rejeitados em dezenas de projetos open source.

2. **Kalliamvakou et al. (2014)** â€” *The Promises and Perils of Mining GitHub*  
   ğŸ”— https://chisel.cs.uvic.ca/pubs/kalliamvakou-MSR2014.pdf  
   Discute limitaÃ§Ãµes dos dados da plataforma e riscos ao minerar GitHub sem critÃ©rios rigorosos.

3. **Yang et al. (2024)** â€” *A Survey on Modern Code Review: Progresses, Challenges and Opportunities*  
   ğŸ”— https://github.com/watreyoung/MCR-Survey  
   Apresenta o estado da arte em revisÃ£o de cÃ³digo moderna.

4. **Vidoni (2022)** â€” *A systematic process for Mining Software Repositories*  
   ğŸ”— https://www.sciencedirect.com/science/article/pii/S0950584921002317  
   SLR sobre tÃ©cnicas e desafios da mineraÃ§Ã£o de repositÃ³rios.

5. **Wessel et al. (2023)** â€” *GitHub Actions: The Impact on the Pull Request Process*  
   ğŸ”— https://www.ime.usp.br/~gerosa/papers/Wessel_EMSE_Actions.pdf  
   Investiga como automaÃ§Ãµes afetam PRs.

Essas evidÃªncias reforÃ§am a relevÃ¢ncia cientÃ­fica do tema e a necessidade de ferramentas de mineraÃ§Ã£o mais acessÃ­veis e automatizadas.

---

### 2.4 Referencial teÃ³rico e empÃ­rico essencial

O experimento fundamenta-se em quatro eixos:

#### **(1) MineraÃ§Ã£o de RepositÃ³rios de Software (MSR)**  
Base teÃ³rica para extrair e analisar artefatos como PRs.  
ReferÃªncia:  
ğŸ”— Kalliamvakou et al. (2014) â€“ https://chisel.cs.uvic.ca/pubs/kalliamvakou-MSR2014.pdf

#### **(2) MÃ©tricas de Pull Requests**  
MÃ©tricas como tamanho, interaÃ§Ã£o e tempo de anÃ¡lise sÃ£o amplamente utilizadas na literatura para caracterizar processos de revisÃ£o.  
ReferÃªncia:  
ğŸ”— Rahman & Roy (2014) â€“ https://dl.acm.org/doi/10.1145/2597073.2597121

#### **(3) Paralelismo e TolerÃ¢ncia a Falhas**  
Conceitos herdados de sistemas distribuÃ­dos orientam o uso de paralelismo e checkpoints para lidar com execuÃ§Ãµes longas.

#### **(4) Interfaces grÃ¡ficas e usabilidade**  
GUI melhora observabilidade e acessibilidade em ferramentas tÃ©cnicas.  
Baseado em princÃ­pios clÃ¡ssicos de IHC (Norman, Nielsen).

---

## 3. Objetivos e questÃµes (Goal / Question / Metric)

### 3.1 Objetivo geral (Goal Template)

**Analisar** a eficÃ¡cia de um software com interface grÃ¡fica para mineraÃ§Ã£o automatizada de repositÃ³rios GitHub e coleta de mÃ©tricas de Pull Requests, **com o propÃ³sito de** avaliar sua eficiÃªncia, confiabilidade, completude e usabilidade, **sob a perspectiva** de pesquisadores e usuÃ¡rios tÃ©cnicos, **no contexto** de estudos empÃ­ricos em Engenharia de Software que demandam extraÃ§Ã£o de dados em larga escala.

### 3.2 Objetivos especÃ­ficos

- **OE1 â€“ EficiÃªncia:** Avaliar se o software GUI melhora o desempenho da mineraÃ§Ã£o em termos de tempo total, throughput e paralelismo.
- **OE2 â€“ Confiabilidade:** Avaliar a resiliÃªncia do processo, especialmente quanto Ã  recuperaÃ§Ã£o via checkpoints e reduÃ§Ã£o de falhas.
- **OE3 â€“ Completude:** Avaliar se as mÃ©tricas de PRs coletadas pela ferramenta sÃ£o completas e consistentes em relaÃ§Ã£o ao baseline tradicional.
- **OE4 â€“ Usabilidade:** Avaliar a acessibilidade e facilidade de uso do software para usuÃ¡rios com nÃ­veis variados de experiÃªncia.

### 3.3 QuestÃµes de pesquisa

#### **Para OE1 â€“ EficiÃªncia**
- **Q1.1:** O software reduz o tempo total de mineraÃ§Ã£o?
- **Q1.2:** O software aumenta o throughput (PRs/min, repos/hora)?
- **Q1.3:** O uso de paralelismo no software melhora o desempenho?

#### **Para OE2 â€“ Confiabilidade**
- **Q2.1:** O software apresenta menos falhas que o mÃ©todo tradicional?
- **Q2.2:** Os checkpoints permitem retomada eficaz apÃ³s interrupÃ§Ãµes?
- **Q2.3:** O sistema registra e sinaliza erros de forma adequada?

#### **Para OE3 â€“ Completude**
- **Q3.1:** O software coleta a mesma quantidade de PRs que o mÃ©todo baseline?
- **Q3.2:** As mÃ©tricas de PR sÃ£o equivalentes entre mÃ©todos?
- **Q3.3:** HÃ¡ perda de dados causada pelo paralelismo?

#### **Para OE4 â€“ Usabilidade**
- **Q4.1:** Os usuÃ¡rios conseguem completar tarefas sem dificuldade?
- **Q4.2:** A interface grÃ¡fica Ã© percebida como intuitiva?
- **Q4.3:** Os usuÃ¡rios preferem a GUI ao mÃ©todo tradicional?

### 3.4 MÃ©tricas associadas (GQM)

#### **Tabela GQM**

| Objetivo | Pergunta | MÃ©tricas associadas |
|----------|----------|----------------------|
| OE1 | Q1.1 | M1 â€“ Tempo total de execuÃ§Ã£o; M2 â€“ Tempo mÃ©dio por repositÃ³rio |
| OE1 | Q1.2 | M3 â€“ PRs/min; M4 â€“ RepositÃ³rios/hora |
| OE1 | Q1.3 | M5 â€“ Tempo mÃ©dio por thread; M6 â€“ Speedup |
| OE2 | Q2.1 | M7 â€“ Taxa de falhas; M8 â€“ InterrupÃ§Ãµes nÃ£o tratadas |
| OE2 | Q2.2 | M9 â€“ Progresso recuperado; M10 â€“ Tempo de retomada |
| OE2 | Q2.3 | M11 â€“ Eventos de erro registrados; M12 â€“ Tempo de detecÃ§Ã£o |
| OE3 | Q3.1 | M13 â€“ Percentual de PRs coletados; M14 â€“ DiferenÃ§a absoluta de PRs |
| OE3 | Q3.2 | M15 â€“ CorrelaÃ§Ã£o entre mÃ©tricas; M16 â€“ DiferenÃ§a mÃ©dia |
| OE3 | Q3.3 | M17 â€“ PRs perdidos por thread; M18 â€“ MÃ©tricas incompletas (%) |
| OE4 | Q4.1 | M19 â€“ Tempo para completar tarefa; M20 â€“ Taxa de sucesso |
| OE4 | Q4.2 | M21 â€“ SUS Score; M22 â€“ Erros cometidos pelo usuÃ¡rio |
| OE4 | Q4.3 | M23 â€“ PreferÃªncia declarada; M24 â€“ SatisfaÃ§Ã£o geral |

---

### **Tabela abrangente de mÃ©tricas**

| CÃ³digo | Nome da mÃ©trica | DescriÃ§Ã£o | Unidade | Fonte dos dados |
|--------|------------------|-----------|----------|------------------|
| M1 | Tempo total de execuÃ§Ã£o | Tempo total do processo de mineraÃ§Ã£o | minutos | logs do sistema |
| M2 | Tempo mÃ©dio por repositÃ³rio | MÃ©dia de tempo gasto em cada repositÃ³rio | minutos | logs do sistema |
| M3 | PRs por minuto | Throughput da mineraÃ§Ã£o | PR/min | contagem de PRs |
| M4 | RepositÃ³rios por hora | Fluxo de processamento | repos/hora | logs do sistema |
| M5 | Tempo mÃ©dio por thread | Tempo mÃ©dio de execuÃ§Ã£o paralela | minutos | logs de threads |
| M6 | Speedup | RazÃ£o entre execuÃ§Ã£o paralela e sequencial | adimensional | comparaÃ§Ã£o experimental |
| M7 | Taxa de falhas | ProporÃ§Ã£o de execuÃ§Ãµes com erros | % | relatÃ³rios de erro |
| M8 | InterrupÃ§Ãµes nÃ£o tratadas | Falhas que nÃ£o foram recuperadas | contagem | logs |
| M9 | Progresso recuperado | Percentual restaurado apÃ³s retomada | % | checkpoints |
| M10 | Tempo de retomada | Tempo entre falha e retomada | segundos | tempo de execuÃ§Ã£o |
| M11 | Eventos de erro | NÃºmero de erros detectados | contagem | logs |
| M12 | Tempo de detecÃ§Ã£o de falha | Tempo atÃ© identificar erro | segundos | logs |
| M13 | Percentual de PRs coletados | % de PRs coletados vs baseline | % | comparaÃ§Ã£o de datasets |
| M14 | DiferenÃ§a de PRs | Quantidade absoluta coletada a menos ou a mais | contagem | datasets |
| M15 | CorrelaÃ§Ã£o entre mÃ©tricas | CorrelaÃ§Ã£o Pearson/Spearman entre mÃ©todos | coeficiente | cÃ¡lculo estatÃ­stico |
| M16 | DiferenÃ§a mÃ©dia das mÃ©tricas | DiferenÃ§as absolutas normalizadas | valor mÃ©dio | estatÃ­stica |
| M17 | PRs perdidos por thread | PRs descartados por falha de thread | contagem | logs |
| M18 | MÃ©tricas incompletas | Percentual de PRs com campos ausentes | % | dataset final |
| M19 | Tempo para completar tarefa | Tempo para usuÃ¡rio executar aÃ§Ã£o | minutos | teste de usabilidade |
| M20 | Taxa de sucesso | % de tarefas concluÃ­das sem erro | % | sessÃ£o de testes |
| M21 | SUS Score | Nota do System Usability Scale | pontos (0â€“100) | questionÃ¡rio SUS |
| M22 | Erros do usuÃ¡rio | Quantidade de erros cometidos | contagem | observaÃ§Ã£o |
| M23 | PreferÃªncia declarada | % de usuÃ¡rios que preferem a GUI | % | questionÃ¡rio |
| M24 | SatisfaÃ§Ã£o geral | AvaliaÃ§Ã£o do usuÃ¡rio | Likert (1â€“5) | questionÃ¡rio |

---

## 4. Escopo e contexto do experimento

### 4.1 Escopo funcional / de processo

**IncluÃ­do:**
- execuÃ§Ã£o do software GUI para mineraÃ§Ã£o de PRs;
- comparaÃ§Ã£o com baseline baseado em scripts;
- coleta de mÃ©tricas de eficiÃªncia, confiabilidade e completude;
- aplicaÃ§Ã£o de testes de usabilidade.

**ExcluÃ­do:**
- anÃ¡lise qualitativa do conteÃºdo dos PRs;
- uso de APIs privadas ou datasets externos;
- avaliaÃ§Ã£o do cÃ³digo interno do software.

### 4.2 Contexto do estudo

O estudo ocorrerÃ¡ em ambiente acadÃªmico, no contexto de um projeto de Engenharia de Software. Os participantes incluem estudantes e pesquisadores com familiaridade intermediÃ¡ria com GitHub. O projeto analisado nÃ£o Ã© crÃ­tico, mas envolve manipulaÃ§Ã£o de grande volume de dados e execuÃ§Ã£o prolongada.

### 4.3 Premissas

- A API do GitHub estarÃ¡ funcional durante o experimento.  
- O ambiente terÃ¡ conexÃ£o estÃ¡vel.  
- Os participantes terÃ£o conhecimento bÃ¡sico sobre PRs.  
- O software GUI estarÃ¡ funcional e estÃ¡vel para testes.

### 4.4 RestriÃ§Ãµes

- Tempo limitado de execuÃ§Ã£o em laboratÃ³rio;  
- Disponibilidade limitada de tokens da API GitHub;  
- Equipamentos com desempenho heterogÃªneo;  
- Amostra pequena de usuÃ¡rios para testes.

### 4.5 LimitaÃ§Ãµes previstas

- Resultados podem nÃ£o generalizar para ambientes industriais;  
- A variabilidade de comportamento da API pode afetar a mediÃ§Ã£o;  
- Perfil limitado dos participantes reduz validade externa.

---

## 5. Stakeholders e impacto esperado

### 5.1 Stakeholders principais

- Pesquisadores  
- Estudantes  
- Professores/orientadores  
- Desenvolvedores  
- Comunidade MSR  

### 5.2 Interesses e expectativas

| Stakeholder | Expectativas |
|-------------|--------------|
| Pesquisadores | Maior produtividade, datasets consistentes |
| Estudantes | Ferramenta fÃ¡cil de usar |
| Professores | Estudos reprodutÃ­veis |
| Desenvolvedores | AnÃ¡lises internas de code review |
| Comunidade MSR | Metodologia replicÃ¡vel |

### 5.3 Impactos potenciais

- ReduÃ§Ã£o de tempo de mineraÃ§Ã£o;  
- Aumento da confiabilidade da coleta;  
- FacilitaÃ§Ã£o de estudos empÃ­ricos;  
- PossÃ­vel modificaÃ§Ã£o do processo tradicional de coleta de dados.  

---

## 6. Riscos de alto nÃ­vel, premissas e critÃ©rios de sucesso

### 6.1 Riscos de alto nÃ­vel

- Falhas de rede ou API do GitHub;  
- Dados incompletos por limitaÃ§Ãµes de request;  
- Baixa aceitaÃ§Ã£o da GUI pelos usuÃ¡rios;  
- Falhas crÃ­ticas sem recuperaÃ§Ã£o via checkpoint.

### 6.2 CritÃ©rios de sucesso globais

- Coleta de â‰¥ 95% dos PRs do baseline;  
- Tempo de execuÃ§Ã£o â‰¤ baseline;  
- SUS â‰¥ 70;  
- Taxa de falhas reduzida ou mitigada.

### 6.3 CritÃ©rios de parada antecipada

- Indisponibilidade da API GitHub;  
- Falha crÃ­tica no software GUI;  
- Ambiente inadequado para execuÃ§Ã£o;  
- MudanÃ§a de escopo institucional.

---

## 7. Modelo conceitual e hipÃ³teses

### 7.1 Modelo conceitual do experimento

O experimento baseia-se na premissa de que a **forma de execuÃ§Ã£o do processo de mineraÃ§Ã£o de Pull Requests (GUI vs Script)** atua como um fator que **modifica o comportamento do sistema de coleta de dados** em trÃªs dimensÃµes principais:

1. **EficiÃªncia**
   - Tempo total de execuÃ§Ã£o
   - Throughput (PRs/min, repositÃ³rios/hora)
   - Speedup obtido pelo paralelismo da GUI

2. **Confiabilidade**
   - OcorrÃªncia de falhas
   - Capacidade de retomada via checkpoints
   - Estabilidade da execuÃ§Ã£o

3. **Completude**
   - Quantidade de PRs coletados
   - Integridade das mÃ©tricas de PR
   - ConsistÃªncia entre execuÃ§Ãµes

Essas dimensÃµes, influenciadas pelo fator â€œForma de ExecuÃ§Ã£oâ€, refletem-se diretamente nas **mÃ©tricas produzidas no dataset final**, permitindo avaliar rigorosamente o impacto entre os dois mÃ©todos.

---

### 7.2 HipÃ³teses formais (H0, H1)

#### EficiÃªncia
- **H0-E1:** NÃ£o hÃ¡ diferenÃ§a significativa no tempo total de mineraÃ§Ã£o entre GUI e Script.  
- **H1-E1:** A GUI reduz o tempo total de mineraÃ§Ã£o.

- **H0-E2:** O throughput nÃ£o difere entre os mÃ©todos.  
- **H1-E2:** A GUI aumenta o throughput.

#### Confiabilidade
- **H0-C1:** A taxa de falhas Ã© equivalente entre GUI e Script.  
- **H1-C1:** A GUI apresenta menor taxa de falhas.

- **H0-C2:** O uso de checkpoints nÃ£o melhora a retomada.  
- **H1-C2:** A GUI possibilita retomada mais eficaz.

#### Completude
- **H0-K1:** A quantidade de PRs coletados Ã© igual nos dois mÃ©todos.  
- **H1-K1:** HÃ¡ diferenÃ§a significativa na quantidade de PRs coletados.

- **H0-K2:** As mÃ©tricas coletadas sÃ£o equivalentes entre os mÃ©todos.  
- **H1-K2:** As mÃ©tricas coletadas diferem significativamente.

---

### 7.3 NÃ­vel de significÃ¢ncia e consideraÃ§Ãµes de poder

- **NÃ­vel de significÃ¢ncia**: Î± = 0,05  
- **Poder estatÃ­stico esperado**: â‰¥ 0,80  

A grande quantidade de PRs e repositÃ³rios envolvidos tende a fornecer tamanho amostral adequado para detecÃ§Ã£o de diferenÃ§as reais entre os tratamentos.

---

## 8. VariÃ¡veis, fatores, tratamentos e objetos de estudo

### 8.1 Objetos de estudo
- RepositÃ³rios GitHub selecionados.
- Conjuntos de Pull Requests vÃ¡lidos.
- ExecuÃ§Ãµes completas dos processos de coleta via GUI e via Script.

---

### 8.2 Sujeitos / participantes (visÃ£o geral)
- Pesquisadores, estudantes ou usuÃ¡rios tÃ©cnicos.
- ResponsÃ¡veis apenas por acionar os mÃ©todos e registrar resultados.

---

### 8.3 VariÃ¡veis independentes (fatores) e seus nÃ­veis

| Tipo | Nome | DescriÃ§Ã£o | NÃ­veis |
|------|------|------------|--------|
| Fator principal | Forma de execuÃ§Ã£o | MÃ©todo utilizado para minerar PRs | GUI, Script |

---

### 8.4 Tratamentos (condiÃ§Ãµes experimentais)

| Tratamento | DescriÃ§Ã£o |
|------------|-----------|
| T1 â€” GUI | ExecuÃ§Ã£o completa utilizando o software com interface grÃ¡fica |
| T2 â€” Script | ExecuÃ§Ã£o completa utilizando scripts tradicionais em linha de comando |

---

### 8.5 VariÃ¡veis dependentes (respostas)

| VariÃ¡vel | DescriÃ§Ã£o |
|----------|-----------|
| Tempo total | Tempo total de mineraÃ§Ã£o |
| Throughput | PRs por minuto / repositÃ³rios por hora |
| Speedup | Ganho relativo obtido com paralelismo |
| Taxa de falhas | ProporÃ§Ã£o de execuÃ§Ãµes com erros |
| PRs coletados | Quantidade total de PRs coletados |
| Qualidade das mÃ©tricas | Completude e consistÃªncia dos dados |

---

### 8.6 VariÃ¡veis de controle / bloqueio

| VariÃ¡vel | Como serÃ¡ controlada |
|----------|-----------------------|
| Lista de repositÃ³rios | Mesma lista em ambos os mÃ©todos |
| Ambiente | Mesma mÃ¡quina e conexÃ£o |
| Tokens da API | Mesma distribuiÃ§Ã£o e quantidade |
| PerÃ­odo | ExecuÃ§Ãµes realizadas no mesmo intervalo |

---

### 8.7 VariÃ¡veis de confusÃ£o conhecidas

| PossÃ­vel confusor | EstratÃ©gia de mitigaÃ§Ã£o |
|-------------------|--------------------------|
| Instabilidade da API do GitHub | Monitoramento e repetiÃ§Ã£o controlada |
| OscilaÃ§Ãµes de rede | Ambiente fixo e monitorado |
| Comportamento de threads | ExecuÃ§Ãµes replicadas e logs detalhados |

---

### Tabela geral de variÃ¡veis

| Tipo | Nome | DescriÃ§Ã£o |
|------|------|------------|
| Independente | Forma de execuÃ§Ã£o | GUI vs Script |
| Dependente | Tempo total | Medida de eficiÃªncia |
| Dependente | Throughput | Fluxo de processamento |
| Dependente | Speedup | Ganho obtido em paralelismo |
| Dependente | Taxa de falhas | Confiabilidade |
| Dependente | PRs coletados | Completude |
| Dependente | DiferenÃ§a das mÃ©tricas | Qualidade dos dados |
| Controle | RepositÃ³rios | Lista fixa |
| Controle | Ambiente | Hardware/software idÃªnticos |
| ConfusÃ£o | API GitHub | VariÃ¡vel externa |

---

### Tabela de fatores, tratamentos e combinaÃ§Ãµes

Como o experimento possui apenas um fator binÃ¡rio, as combinaÃ§Ãµes sÃ£o simples:

| Fator | NÃ­veis | CombinaÃ§Ã£o |
|-------|--------|------------|
| Forma de execuÃ§Ã£o | GUI | GUI |
| Forma de execuÃ§Ã£o | Script | Script |

---

## 9. Desenho experimental

### 9.1 Tipo de desenho
Desenho **completamente randomizado**, com dois tratamentos (GUI e Script).  
Adequado porque:

- RepositÃ³rios sÃ£o independentes.
- ExecuÃ§Ã£o automÃ¡tica evita efeitos de aprendizagem.
- Simplicidade e robustez em comparaÃ§Ãµes diretas.

---

### 9.2 RandomizaÃ§Ã£o e alocaÃ§Ã£o
- RepositÃ³rios serÃ£o distribuÃ­dos aleatoriamente entre os dois tratamentos.
- A ordem das execuÃ§Ãµes tambÃ©m serÃ¡ randomizada.
- SerÃ¡ utilizada uma semente fixa (**seed = 42**) para manter reprodutibilidade.

---

### 9.3 Balanceamento e contrabalanÃ§o
- A divisÃ£o serÃ¡ balanceada (mesmo nÃºmero aproximado de repositÃ³rios por tratamento).
- O contrabalanÃ§o pode ser aplicado por meio de inversÃ£o da ordem de execuÃ§Ã£o (GUI â†’ Script e Script â†’ GUI), se necessÃ¡rio.
- Como o processo Ã© automatizado, os efeitos de ordem sÃ£o negligenciÃ¡veis.

---

### 9.4 NÃºmero de grupos e sessÃµes
- **Grupos:** 2 (GUI e Script)
- **SessÃµes:** Cada grupo executarÃ¡ o processo completo uma vez, com possibilidade de repetiÃ§Ã£o para reforÃ§ar anÃ¡lise estatÃ­stica.

---

## 10. PopulaÃ§Ã£o, sujeitos e amostragem

### 10.1 PopulaÃ§Ã£o-alvo
A populaÃ§Ã£o-alvo consiste em usuÃ¡rios tÃ©cnicos que realizam mineraÃ§Ã£o de dados em repositÃ³rios GitHub, incluindo:
- Pesquisadores de Engenharia de Software
- Estudantes com experiÃªncia em Git e GitHub
- Profissionais que utilizam anÃ¡lises de PRs para pesquisa ou desenvolvimento

---

### 10.2 CritÃ©rios de inclusÃ£o de sujeitos
- Conhecimento bÃ¡sico/intermediÃ¡rio de Git e GitHub  
- Capacidade de executar scripts e/ou ferramentas GUI  
- Disponibilidade para participar de todas as etapas  
- Capacidade de interpretaÃ§Ã£o bÃ¡sica de mÃ©tricas  

---

### 10.3 CritÃ©rios de exclusÃ£o de sujeitos
- Nunca ter utilizado GitHub  
- Inabilidade para operar scripts ou GUI  
- Impossibilidade de realizar todas as sessÃµes  
- Conflitos diretos com o desenvolvimento da ferramenta  

---

### 10.4 Tamanho da amostra planejado (por grupo)
- 6 a 10 participantes  
- Divididos igualmente entre GUI e Script  
- O tamanho amostral humano Ã© pequeno, mas os objetos (PRs e repositÃ³rios) garantem volume estatÃ­stico adequado.

---

### 10.5 MÃ©todo de seleÃ§Ã£o / recrutamento
- Amostragem por conveniÃªncia  
- Convite enviado a estudantes e pesquisadores do laboratÃ³rio ou da disciplina  
- ConfirmaÃ§Ã£o de participaÃ§Ã£o via formulÃ¡rio  

---

### 10.6 Treinamento e preparaÃ§Ã£o dos sujeitos
Os participantes receberÃ£o:
- Guia rÃ¡pido da GUI  
- Guia rÃ¡pido dos scripts  
- Checklist operacional  
- Roteiro de execuÃ§Ã£o  
- Ambiente configurado com tokens e repositÃ³rios  

---

## 11. InstrumentaÃ§Ã£o e protocolo operacional

### 11.1 Instrumentos de coleta

| Instrumento | FunÃ§Ã£o |
|-------------|--------|
| AplicaÃ§Ã£o GUI | ExecuÃ§Ã£o paralela com checkpoints |
| Scripts tradicionais | Baseline de comparaÃ§Ã£o |
| Logs gerados automaticamente | Registro de tempo, falhas, throughput |
| CSV final | ConsolidaÃ§Ã£o das mÃ©tricas dos PRs |
| QuestionÃ¡rio SUS | AvaliaÃ§Ã£o de usabilidade |
| Planilha de mÃ©tricas | ConsolidaÃ§Ã£o final dos dados |
| Roteiro operacional | PadronizaÃ§Ã£o do procedimento |

---

### 11.2 Materiais de suporte
- Manual do usuÃ¡rio da GUI  
- Manual de execuÃ§Ã£o do script  
- Documento com descriÃ§Ã£o das mÃ©tricas  
- Checklist do ambiente  
- Modelo de relatÃ³rio de execuÃ§Ã£o  

---

### 11.3 Procedimento experimental (protocolo â€“ passo a passo)

O processo segue as etapas:

1. Preparar o ambiente  
2. Configurar tokens, instalar GUI e scripts  
3. Distribuir lista fixa de repositÃ³rios  
4. Selecionar e instruir os participantes  
5. Alocar participantes aleatoriamente em GUI ou Script  
6. Realizar execuÃ§Ãµes completas dos tratamentos  
7. Coletar logs, CSVs e mÃ©tricas  
8. Aplicar questionÃ¡rio SUS  
9. Consolidar dados  
10. Preparar dataset final para anÃ¡lises estatÃ­sticas  

---

### Fluxograma do processo operacional

```mermaid
flowchart TD

    A[InÃ­cio do Experimento] --> B[PreparaÃ§Ã£o do Ambiente]
    B --> B1[Configurar tokens de API]
    B --> B2[Instalar e validar GUI]
    B --> B3[Disponibilizar scripts tradicionais]
    B --> B4[Distribuir lista fixa de repositÃ³rios]

    B4 --> C[SeleÃ§Ã£o e PreparaÃ§Ã£o dos Participantes]
    C --> C1[Verificar critÃ©rios de inclusÃ£o]
    C --> C2[Aplicar instruÃ§Ãµes padronizadas]
    C --> C3[Randomizar participantes nos tratamentos]

    C3 --> D[ExecuÃ§Ã£o dos Tratamentos]
    D --> D1[Grupo GUI - Executar mineraÃ§Ã£o com interface grÃ¡fica]
    D --> D2[Grupo Script - Executar mineraÃ§Ã£o via linha de comando]

    D1 --> E[Coleta de Dados Operacionais]
    D2 --> E

    E --> E1[Extrair mÃ©tricas: tempo, throughput, falhas]
    E --> E2[Registrar PRs coletados e completude]
    E --> E3[Salvar logs e resultados CSV]

    E3 --> F[AvaliaÃ§Ã£o PÃ³s-ExecuÃ§Ã£o]
    F --> F1[Aplicar QuestionÃ¡rio SUS]
    F --> F2[Coletar feedback qualitativo]

    F --> G[ConsolidaÃ§Ã£o dos Dados]
    G --> G1[Unificar CSVs]
    G --> G2[Gerar dataset final padronizado]

    G2 --> H[Fim - Pronto para AnÃ¡lise EstatÃ­stica]
```
---
    
### 11.4 Plano de piloto

O piloto terÃ¡ as seguintes caracterÃ­sticas:

- ExecuÃ§Ã£o piloto com **2 participantes**
- Uso de **4 repositÃ³rios** para validar o fluxo completo

Ajustes serÃ£o realizados caso ocorram:

- Falhas operacionais
- InconsistÃªncias nas mÃ©tricas geradas
- Dificuldades relatadas pelos participantes
- Logs insuficientes para anÃ¡lise estatÃ­stica

---

## 12. Plano de anÃ¡lise de dados (prÃ©-execuÃ§Ã£o)

### 12.1 EstratÃ©gia geral de anÃ¡lise

A anÃ¡lise seguirÃ¡ as etapas:

1. Consolidar o dataset final (GUI vs Script)
2. Aplicar testes de normalidade
3. Comparar mÃ©tricas de:
   - EficiÃªncia
   - Confiabilidade
   - Completude
4. Avaliar significÃ¢ncia estatÃ­stica entre os mÃ©todos
5. Avaliar usabilidade via SUS
6. Relacionar resultados com hipÃ³teses H0/H1
7. Gerar conclusÃµes sobre o impacto da ferramenta

---

### 12.2 MÃ©todos estatÃ­sticos planejados

- **Shapiro-Wilk** â€” testar normalidade dos dados  
- **t-test** â€” se houver normalidade  
- **Mannâ€“Whitney U** â€” se nÃ£o houver normalidade  
- **CorrelaÃ§Ã£o de Spearman** â€” avaliar associaÃ§Ã£o entre mÃ©tricas contÃ­nuas  
- **Teste Qui-quadrado** â€” comparar proporÃ§Ãµes de falhas  
- **Intervalos de ConfianÃ§a (95%)** â€” medir precisÃ£o das diferenÃ§as  
- **CÃ¡lculo do SUS Score** â€” medir usabilidade da GUI  

---

### 12.3 Tratamento de dados faltantes e outliers

**Dados faltantes:**
- ExclusÃ£o quando < 5%  
- ImputaÃ§Ã£o simples, se necessÃ¡rio  

**Outliers:**
- AvaliaÃ§Ã£o por:
  - **IQR** (Interquartile Range)
  - **Contexto experimental** (ex.: falha de rede ou API)
- Outliers operacionais serÃ£o documentados e nÃ£o removidos sem justificativa formal

---

### 12.4 Plano de anÃ¡lise para dados qualitativos

Os dados qualitativos (comentÃ¡rios e impressÃµes dos participantes) serÃ£o analisados por:

- **AnÃ¡lise de conteÃºdo**
- **CategorizaÃ§Ã£o temÃ¡tica**, incluindo:
  - Intuitividade
  - Dificuldades
  - PercepÃ§Ã£o geral da ferramenta
- **TriangulaÃ§Ã£o** com SUS Score
- Busca por diferenÃ§as qualitativas entre GUI e Script

---

## 13. AvaliaÃ§Ã£o de validade (ameaÃ§as e mitigaÃ§Ã£o)

### 13.1 Validade de conclusÃ£o
Liste ameaÃ§as que podem comprometer a robustez das conclusÃµes estatÃ­sticas (baixo poder, violaÃ§Ã£o de suposiÃ§Ãµes, erros de medida) e como pretende mitigÃ¡-las.

### 13.2 Validade interna
Identifique ameaÃ§as relacionadas a causas alternativas para os efeitos observados (history, maturation, selection, etc.) e explique suas estratÃ©gias de controle.

### 13.3 Validade de constructo
Refleta se as medidas escolhidas realmente representam os conceitos de interesse e descreva como vocÃª reduzirÃ¡ ambiguidades de interpretaÃ§Ã£o.

### 13.4 Validade externa
Discuta em que contextos os resultados podem ser generalizados e quais diferenÃ§as de cenÃ¡rio podem limitar essa generalizaÃ§Ã£o.

### 13.5 Resumo das principais ameaÃ§as e estratÃ©gias de mitigaÃ§Ã£o
FaÃ§a uma sÃ­ntese das ameaÃ§as mais crÃ­ticas e das aÃ§Ãµes planejadas, de preferÃªncia em forma de lista ou tabela simples.

---

## 14. Ã‰tica, privacidade e conformidade

### 14.1 QuestÃµes Ã©ticas (uso de sujeitos, incentivos, etc.)
Descreva potenciais questÃµes Ã©ticas (pressÃ£o para participar, uso de estudantes, incentivos, riscos de exposiÃ§Ã£o) e como serÃ£o tratadas.

### 14.2 Consentimento informado
Explique como os participantes serÃ£o informados sobre objetivos, riscos, benefÃ­cios e como registrarÃ£o seu consentimento.

### 14.3 Privacidade e proteÃ§Ã£o de dados
Indique que dados pessoais serÃ£o coletados, como serÃ£o protegidos (anonimizaÃ§Ã£o, pseudoanonimizaÃ§Ã£o, controle de acesso) e por quanto tempo serÃ£o mantidos.

### 14.4 AprovaÃ§Ãµes necessÃ¡rias (comitÃª de Ã©tica, jurÃ­dico, DPO, etc.)
Liste Ã³rgÃ£os ou pessoas que precisam aprovar o experimento (comitÃª de Ã©tica, jurÃ­dico, DPO, gestores) e o status atual dessas aprovaÃ§Ãµes.

---

## 15. Recursos, infraestrutura e orÃ§amento

### 15.1 Recursos humanos e papÃ©is
Identifique os membros da equipe do experimento e descreva brevemente o papel e responsabilidade de cada um.

### 15.2 Infraestrutura tÃ©cnica necessÃ¡ria
Liste ambientes, servidores, ferramentas, repositÃ³rios e integraÃ§Ãµes que devem estar disponÃ­veis para executar o experimento.

### 15.3 Materiais e insumos
Relacione materiais fÃ­sicos ou digitais necessÃ¡rios (mÃ¡quinas, licenÃ§as, formulÃ¡rios, dispositivos) que precisam estar prontos antes da operaÃ§Ã£o.

### 15.4 OrÃ§amento e custos estimados
FaÃ§a uma estimativa dos principais custos envolvidos (horas de pessoas, serviÃ§os, licenÃ§as, infraestrutura) e a fonte de financiamento.

---

## 16. Cronograma, marcos e riscos operacionais

### 16.1 Macrocronograma (atÃ© o inÃ­cio da execuÃ§Ã£o)
Defina as principais datas e marcos (conclusÃ£o do plano, piloto, revisÃ£o, inÃ­cio da operaÃ§Ã£o) com uma visÃ£o de tempo realista.

### 16.2 DependÃªncias entre atividades
Indique quais atividades dependem de outras para comeÃ§ar (por exemplo, treinamento apÃ³s aprovaÃ§Ã£o Ã©tica), deixando essas dependÃªncias claras.

### 16.3 Riscos operacionais e plano de contingÃªncia
Liste riscos ligados a cronograma, disponibilidade de pessoas ou recursos, e descreva aÃ§Ãµes de contingÃªncia caso esses riscos se materializem.

---

## 17. GovernanÃ§a do experimento

### 17.1 PapÃ©is e responsabilidades formais
Defina quem decide, quem executa, quem revisa e quem apenas deve ser informado, deixando claro o fluxo de responsabilidade.

### 17.2 Ritos de acompanhamento prÃ©-execuÃ§Ã£o
Descreva as reuniÃµes, checkpoints e revisÃµes previstos antes da execuÃ§Ã£o, incluindo frequÃªncia e participantes.

### 17.3 Processo de controle de mudanÃ§as no plano
Explique como mudanÃ§as no desenho ou no escopo do experimento serÃ£o propostas, analisadas, aprovadas e registradas.

---

## 18. Plano de documentaÃ§Ã£o e reprodutibilidade

### 18.1 RepositÃ³rios e convenÃ§Ãµes de nomeaÃ§Ã£o
Indique onde o plano, instrumentos, scripts e dados (futuros) serÃ£o armazenados e quais convenÃ§Ãµes de nomes serÃ£o usadas.

### 18.2 Templates e artefatos padrÃ£o
Liste os modelos (questionÃ¡rios, formulÃ¡rios, checklists, scripts) que serÃ£o usados e onde podem ser encontrados.

### 18.3 Plano de empacotamento para replicaÃ§Ã£o futura
Descreva o que serÃ¡ organizado desde jÃ¡ (documentos, scripts, instruÃ§Ãµes) para facilitar a replicaÃ§Ã£o do experimento por outras equipes ou no futuro.

---

## 19. Plano de comunicaÃ§Ã£o

### 19.1 PÃºblicos e mensagens-chave prÃ©-execuÃ§Ã£o
Liste os grupos que precisam ser comunicados e quais mensagens principais devem receber (objetivos, escopo, datas, impactos esperados).

### 19.2 Canais e frequÃªncia de comunicaÃ§Ã£o
Defina por quais canais (e-mail, reuniÃµes, Slack/Teams, etc.) e com que frequÃªncia as comunicaÃ§Ãµes serÃ£o feitas.

### 19.3 Pontos de comunicaÃ§Ã£o obrigatÃ³rios
Especifique os eventos que exigem comunicaÃ§Ã£o formal (aprovaÃ§Ã£o do plano, mudanÃ§as relevantes, adiamentos, cancelamentos).

---

## 20. CritÃ©rios de prontidÃ£o para execuÃ§Ã£o (Definition of Ready)

### 20.1 Checklist de prontidÃ£o (itens que devem estar completos)
Liste os itens que precisam estar finalizados e aprovados (plano, instrumentos, aprovaÃ§Ã£o Ã©tica, recursos, comunicaÃ§Ã£o) para autorizar o inÃ­cio da operaÃ§Ã£o.

### 20.2 AprovaÃ§Ãµes finais para iniciar a operaÃ§Ã£o
Indique quem precisa dar o â€œok finalâ€ (nomes ou cargos) e como esse aceite serÃ¡ registrado antes da execuÃ§Ã£o comeÃ§ar.





